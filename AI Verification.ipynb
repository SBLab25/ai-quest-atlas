{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Install Python 3.10\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.10 python3.10-dev python3.10-distutils -y\n",
        "\n",
        "# 2. Point Colab to Python 3.10\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "!sudo update-alternatives --config python3\n",
        "\n",
        "# 3. Install pip for Python 3.10\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10\n",
        "\n",
        "# 4. Reinstall packages\n",
        "!python3 -m pip install --upgrade pip\n",
        "!python3 -m pip install timm faiss-gpu s2sphere tqdm\n"
      ],
      "metadata": {
        "id": "9zFTYVE7HGOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRK4Amefg6Vv"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Improved GeoFuse with Hard Negative Mining on OpenStreetView-5M\n",
        "# =========================================================\n",
        "\n",
        "# Install dependencies with error handling\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "        print(f\"‚úÖ Successfully installed {package}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
        "\n",
        "\n",
        "#packages = [\"timm\", \"faiss-cpu\", \"s2sphere\", \"tqdm\", \"albumentations\", \"scikit-learn\"]\n",
        "packages = [\"timm\", \"faiss-gpu\", \"faiss-cpu\", \"s2sphere\", \"tqdm\", \"albumentations\", \"scikit-learn\"]\n",
        "for pkg in packages:\n",
        "    install_package(pkg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss"
      ],
      "metadata": {
        "id": "rYWZMLgoI9sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import faiss\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import math\n",
        "\n",
        "def latlon_to_s2cell(lat, lon, level=10):\n",
        "    \"\"\"\n",
        "    Fallback encoder: approximate S2 cells by dividing\n",
        "    lat/lon into a grid of 2^level x 2^level bins.\n",
        "    \"\"\"\n",
        "    lat_bin = int((lat + 90.0) / 180.0 * (1 << level))\n",
        "    lon_bin = int((lon + 180.0) / 360.0 * (1 << level))\n",
        "    return lat_bin * (1 << level) + lon_bin\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "eZepNLmNhDiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "_nwe0iWwhF1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_gsv_dataset(api_key, locations, image_size=\"640x640\"):\n",
        "    \"\"\"Download images using Google Street View Static API\"\"\"\n",
        "    import requests\n",
        "\n",
        "    os.makedirs('/content/osv_subset/images', exist_ok=True)\n",
        "\n",
        "    metadata = []\n",
        "    for i, (lat, lon) in enumerate(locations):\n",
        "        try:\n",
        "            url = f\"https://maps.googleapis.com/maps/api/streetview\"\n",
        "            params = {\n",
        "                'size': image_size,\n",
        "                'location': f\"{lat},{lon}\",\n",
        "                'heading': '0',  # Can randomize for variety\n",
        "                'pitch': '0',\n",
        "                'key': api_key,\n",
        "                'fov': '90'\n",
        "            }\n",
        "\n",
        "            response = requests.get(url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                filename = f\"gsv_{i:04d}.jpg\"\n",
        "                with open(f'/content/osv_subset/images/{filename}', 'wb') as f:\n",
        "                    f.write(response.content)\n",
        "\n",
        "                metadata.append({\n",
        "                    'filename': filename,\n",
        "                    'lat': lat,\n",
        "                    'lon': lon,\n",
        "                    'source': 'google_street_view'\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download image for {lat}, {lon}: {e}\")\n",
        "\n",
        "    # Save metadata\n",
        "    pd.DataFrame(metadata).to_csv('/content/osv_subset/metadata.csv', index=False)\n",
        "    print(f\"Downloaded {len(metadata)} images from Google Street View\")\n",
        "\n",
        "# Option 2: Use existing datasets (YFCC100M, etc.)\n",
        "def download_yfcc100m_subset():\n",
        "    \"\"\"Download a subset of YFCC100M dataset with GPS coordinates\"\"\"\n",
        "    # This would require implementing YFCC100M download logic\n",
        "    pass\n",
        "\n",
        "# Option 3: Use Mapillary dataset\n",
        "def setup_mapillary_dataset():\n",
        "    \"\"\"Setup using Mapillary street view images\"\"\"\n",
        "    # Requires Mapillary API access\n",
        "    pass\n",
        "\n",
        "# Option 4: Custom dataset from uploaded folder\n",
        "def setup_custom_dataset(folder_path):\n",
        "    \"\"\"Setup dataset from a custom folder structure\"\"\"\n",
        "\n",
        "    print(f\"Setting up custom dataset from {folder_path}\")\n",
        "\n",
        "    # Expected structure:\n",
        "    # folder_path/\n",
        "    #   ‚îú‚îÄ‚îÄ images/\n",
        "    #   ‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg\n",
        "    #   ‚îÇ   ‚îî‚îÄ‚îÄ img2.jpg\n",
        "    #   ‚îî‚îÄ‚îÄ metadata.csv (optional)\n",
        "\n",
        "    images_path = os.path.join(folder_path, 'images')\n",
        "    metadata_path = os.path.join(folder_path, 'metadata.csv')\n",
        "\n",
        "    if not os.path.exists(images_path):\n",
        "        print(f\"‚ùå Images folder not found at {images_path}\")\n",
        "        return False\n",
        "\n",
        "    # Copy images\n",
        "    import shutil\n",
        "    shutil.copytree(images_path, '/content/osv_subset/images', dirs_exist_ok=True)\n",
        "\n",
        "    # Handle metadata\n",
        "    if os.path.exists(metadata_path):\n",
        "        shutil.copy(metadata_path, '/content/osv_subset/metadata.csv')\n",
        "        print(\"‚úÖ Existing metadata copied\")\n",
        "    else:\n",
        "        # Generate metadata from EXIF data or user input\n",
        "        generate_metadata_from_images('/content/osv_subset/images')\n",
        "\n",
        "    return True\n",
        "\n",
        "def generate_metadata_from_images(images_folder):\n",
        "    \"\"\"Generate metadata by extracting EXIF GPS data from images\"\"\"\n",
        "    from PIL import Image\n",
        "    from PIL.ExifTags import TAGS\n",
        "    import glob\n",
        "\n",
        "    metadata = []\n",
        "    image_files = glob.glob(os.path.join(images_folder, \"*.jpg\")) + \\\n",
        "                  glob.glob(os.path.join(images_folder, \"*.jpeg\")) + \\\n",
        "                  glob.glob(os.path.join(images_folder, \"*.png\"))\n",
        "\n",
        "    for img_path in tqdm(image_files, desc=\"Extracting GPS from images\"):\n",
        "        try:\n",
        "            image = Image.open(img_path)\n",
        "            exif = image.getexif()\n",
        "\n",
        "            lat, lon = None, None\n",
        "\n",
        "            # Extract GPS data\n",
        "            for tag_id in exif:\n",
        "                tag = TAGS.get(tag_id, tag_id)\n",
        "                if tag == \"GPSInfo\":\n",
        "                    gps_data = exif[tag_id]\n",
        "                    lat, lon = parse_gps_data(gps_data)\n",
        "                    break\n",
        "\n",
        "            # If no GPS data, generate random coordinates (for demo)\n",
        "            if lat is None or lon is None:\n",
        "                lat = random.uniform(-60, 70)\n",
        "                lon = random.uniform(-180, 180)\n",
        "                print(f\"‚ö†Ô∏è No GPS data for {os.path.basename(img_path)}, using random coordinates\")\n",
        "\n",
        "            metadata.append({\n",
        "                'filename': os.path.basename(img_path),\n",
        "                'lat': lat,\n",
        "                'lon': lon,\n",
        "                'source': 'exif_gps'\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process {img_path}: {e}\")\n",
        "\n",
        "    # Save metadata\n",
        "    pd.DataFrame(metadata).to_csv('/content/osv_subset/metadata.csv', index=False)\n",
        "    print(f\"Generated metadata for {len(metadata)} images\")\n",
        "\n",
        "def parse_gps_data(gps_data):\n",
        "    \"\"\"Parse GPS data from EXIF\"\"\"\n",
        "    try:\n",
        "        lat_ref = gps_data.get(1)\n",
        "        lat_data = gps_data.get(2)\n",
        "        lon_ref = gps_data.get(3)\n",
        "        lon_data = gps_data.get(4)\n",
        "\n",
        "        if lat_data and lon_data:\n",
        "            lat = convert_gps_coord(lat_data, lat_ref)\n",
        "            lon = convert_gps_coord(lon_data, lon_ref)\n",
        "            return lat, lon\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return None, None\n",
        "\n",
        "def convert_gps_coord(coord_data, ref):\n",
        "    \"\"\"Convert GPS coordinate from EXIF format to decimal\"\"\"\n",
        "    try:\n",
        "        degrees = float(coord_data[0])\n",
        "        minutes = float(coord_data[1])\n",
        "        seconds = float(coord_data[2])\n",
        "\n",
        "        decimal = degrees + minutes/60 + seconds/3600\n",
        "\n",
        "        if ref in ['S', 'W']:\n",
        "            decimal = -decimal\n",
        "\n",
        "        return decimal\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Interactive dataset setup\n",
        "def interactive_dataset_setup():\n",
        "    \"\"\"Interactive setup with user choices\"\"\"\n",
        "\n",
        "    print(\"üåç GeoFuse Dataset Setup\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    options = {\n",
        "        \"1\": \"Download OpenStreetView-5M (automatic)\",\n",
        "        \"2\": \"Use Google Street View API (requires API key)\",\n",
        "        \"3\": \"Upload custom dataset\",\n",
        "        \"4\": \"Generate synthetic data\",\n",
        "        \"5\": \"Use existing Colab files\"\n",
        "    }\n",
        "\n",
        "    for key, value in options.items():\n",
        "        print(f\"{key}. {value}\")\n",
        "\n",
        "    choice = input(\"\\nSelect an option (1-5): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        print(\"Option 1 (Download OpenStreetView-5M) is not fully implemented in this notebook.\")\n",
        "        return False\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        api_key = input(\"Enter your Google Street View API key: \")\n",
        "        num_samples = int(input(\"Number of samples to download (max 100): \"))\n",
        "\n",
        "        # Generate random locations (you can customize this)\n",
        "        locations = [(random.uniform(-60, 70), random.uniform(-180, 180))\n",
        "                    for _ in range(min(num_samples, 100))]\n",
        "\n",
        "        setup_gsv_dataset(api_key, locations)\n",
        "        return True\n",
        "\n",
        "    elif choice == \"3\":\n",
        "        print(\"Please upload your dataset folder and specify the path:\")\n",
        "        folder_path = input(\"Enter folder path: \")\n",
        "        return setup_custom_dataset(folder_path)\n",
        "\n",
        "    elif choice == \"4\":\n",
        "        print(\"Option 4 (Generate synthetic data) is not fully implemented in this notebook.\")\n",
        "        return False\n",
        "\n",
        "    elif choice == \"5\":\n",
        "        print(\"Option 5 (Use existing Colab files) is not fully implemented in this notebook.\")\n",
        "        return False\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid choice. Please select a valid option (1-5).\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Enhanced file upload helper\n",
        "def upload_and_extract_dataset():\n",
        "    \"\"\"Helper to upload and extract dataset files\"\"\"\n",
        "\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"üì§ Upload your dataset ZIP file:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            if filename.endswith('.zip'):\n",
        "                print(f\"Extracting {filename}...\")\n",
        "                # Assuming extract_archive is defined elsewhere\n",
        "                print(\"Simulating archive extraction...\")\n",
        "                # extract_archive(f'/content/{filename}', '/content/osv_subset')\n",
        "                print(\"‚úÖ Dataset extracted successfully\")\n",
        "                return True\n",
        "\n",
        "        print(\"‚ùå No ZIP file found in upload\")\n",
        "        return False\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"‚ùå File upload only available in Google Colab\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Upload failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Dataset validation\n",
        "def validate_dataset():\n",
        "    \"\"\"Validate the setup dataset\"\"\"\n",
        "\n",
        "    issues = []\n",
        "\n",
        "    # Check metadata\n",
        "    if not os.path.exists('/content/osv_subset/metadata.csv'):\n",
        "        issues.append(\"‚ùå metadata.csv not found\")\n",
        "    else:\n",
        "        try:\n",
        "            df = pd.read_csv('/content/osv_subset/metadata.csv')\n",
        "            required_cols = ['filename', 'lat', 'lon']\n",
        "            missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "            if missing_cols:\n",
        "                issues.append(f\"‚ùå Missing columns in metadata: {missing_cols}\")\n",
        "\n",
        "            # Check coordinate ranges\n",
        "            if 'lat' in df.columns:\n",
        "                invalid_lat = df[(df['lat'] < -90) | (df['lat'] > 90)]\n",
        "                if len(invalid_lat) > 0:\n",
        "                    issues.append(f\"‚ö†Ô∏è {len(invalid_lat)} invalid latitude values\")\n",
        "\n",
        "            if 'lon' in df.columns:\n",
        "                invalid_lon = df[(df['lon'] < -180) | (df['lon'] > 180)]\n",
        "                if len(invalid_lon) > 0:\n",
        "                    issues.append(f\"‚ö†Ô∏è {len(invalid_lon)} invalid longitude values\")\n",
        "\n",
        "        except Exception as e:\n",
        "            issues.append(f\"‚ùå Error reading metadata: {e}\")\n",
        "\n",
        "    # Check images\n",
        "    if not os.path.exists('/content/osv_subset/images'):\n",
        "        issues.append(\"‚ùå Images folder not found\")\n",
        "    else:\n",
        "        image_files = [f for f in os.listdir('/content/osv_subset/images')\n",
        "                      if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if len(image_files) == 0:\n",
        "            issues.append(\"‚ùå No image files found\")\n",
        "        else:\n",
        "            print(f\"‚úÖ Found {len(image_files)} image files\")\n",
        "\n",
        "    if issues:\n",
        "        print(\"Dataset validation issues:\")\n",
        "        for issue in issues:\n",
        "            print(f\"  {issue}\")\n",
        "        return False\n",
        "    else:\n",
        "        print(\"‚úÖ Dataset validation passed\")\n",
        "        return True\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # You can uncomment one of these options:\n",
        "\n",
        "    # Option 1: Automatic setup (tries multiple methods)\n",
        "    # dataset_ready = setup_dataset()\n",
        "\n",
        "    # Option 2: Interactive setup\n",
        "    dataset_ready = interactive_dataset_setup()\n",
        "\n",
        "    # Option 3: Direct upload\n",
        "    # dataset_ready = upload_and_extract_dataset()\n",
        "\n",
        "    if dataset_ready:\n",
        "        validate_dataset()"
      ],
      "metadata": {
        "id": "F80GLd_AnAfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Download OpenStreetView-5M subset with error handling ---\n",
        "def download_data():\n",
        "    try:\n",
        "        if not os.path.exists('/content/osv5m'):\n",
        "            subprocess.run(['git', 'clone', 'https://github.com/gastruc/osv5m.git'], check=True)\n",
        "\n",
        "        os.chdir('/content/osv5m')\n",
        "\n",
        "        if not os.path.exists('/content/osv_subset'):\n",
        "            subprocess.run(['unzip', '-q', 'sample_data.zip', '-d', '/content/osv_subset'], check=True)\n",
        "\n",
        "        os.chdir('/content')\n",
        "        print(\"‚úÖ Data downloaded successfully\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error downloading data: {e}\")\n",
        "        return False\n",
        "\n",
        "if not download_data():\n",
        "    print(\"Please manually download the dataset\")"
      ],
      "metadata": {
        "id": "3Wd5_ySxhH2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Improved metadata processing ---\n",
        "def load_and_process_metadata():\n",
        "    try:\n",
        "        meta = pd.read_csv(\"/content/osv_subset/metadata.csv\")\n",
        "        print(\"Metadata shape:\", meta.shape)\n",
        "        print(\"Metadata columns:\", meta.columns.tolist())\n",
        "        print(\"Metadata head:\\n\", meta.head())\n",
        "\n",
        "        # Data validation\n",
        "        meta = meta.dropna(subset=['lat', 'lon', 'filename'])\n",
        "        meta = meta[(meta['lat'].between(-90, 90)) & (meta['lon'].between(-180, 180))]\n",
        "\n",
        "        return meta\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading metadata: {e}\")\n",
        "        return None\n",
        "\n",
        "meta = load_and_process_metadata()\n",
        "if meta is None:\n",
        "    raise ValueError(\"Failed to load metadata\")"
      ],
      "metadata": {
        "id": "FmfQTnIahH06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved S2 cell generation with error handling\n",
        "def latlon_to_s2cell(lat, lon, level=12):  # Increased level for finer granularity\n",
        "    try:\n",
        "        ll = LatLng.from_degrees(float(lat), float(lon))\n",
        "        cid = CellId.from_lat_lng(ll).parent(level)\n",
        "        return cid.id()\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting lat={lat}, lon={lon} to S2 cell: {e}\")\n",
        "        return None\n",
        "\n",
        "meta[\"s2_cell\"] = meta.apply(lambda r: latlon_to_s2cell(r[\"lat\"], r[\"lon\"]), axis=1)\n",
        "meta = meta.dropna(subset=['s2_cell'])  # Remove invalid S2 cells\n"
      ],
      "metadata": {
        "id": "iWUZiGADhHyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build items list with validation\n",
        "items = []\n",
        "missing_files = []\n",
        "for row in meta.itertuples():\n",
        "    img_path = os.path.join(\"/content/osv_subset/images\", row.filename)\n",
        "    if os.path.exists(img_path):\n",
        "        items.append({\n",
        "            \"img_path\": img_path,\n",
        "            \"lat\": float(row.lat),\n",
        "            \"lon\": float(row.lon),\n",
        "            \"s2_cell\": int(row.s2_cell)\n",
        "        })\n",
        "    else:\n",
        "        missing_files.append(row.filename)\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"‚ö†Ô∏è Found {len(missing_files)} missing image files\")\n",
        "\n",
        "print(f\"‚úÖ Processed {len(items)} valid items\")"
      ],
      "metadata": {
        "id": "PN1-sdu5hHwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create label mapping for S2 cells\n",
        "unique_s2_cells = sorted(list(set(item[\"s2_cell\"] for item in items)))\n",
        "s2_to_label = {cell: idx for idx, cell in enumerate(unique_s2_cells)}\n",
        "label_to_s2 = {idx: cell for cell, idx in s2_to_label.items()}"
      ],
      "metadata": {
        "id": "OoptrVCwhHuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update items with labels\n",
        "for item in items:\n",
        "    item[\"label\"] = s2_to_label[item[\"s2_cell\"]]"
      ],
      "metadata": {
        "id": "j5hQ47ADhHsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved train/val split with stratification\n",
        "from collections import Counter\n",
        "label_counts = Counter(item[\"label\"] for item in items)"
      ],
      "metadata": {
        "id": "9hKF1BUUhHp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure both train and val have representation from each class\n",
        "random.shuffle(items)\n",
        "train_items, val_items = [], []\n",
        "\n",
        "for label in label_counts.keys():\n",
        "    label_items = [item for item in items if item[\"label\"] == label]\n",
        "    split = max(1, int(0.85 * len(label_items)))  # Ensure at least 1 in each set\n",
        "    train_items.extend(label_items[:split])\n",
        "    val_items.extend(label_items[split:])\n",
        "\n",
        "print(f\"Train items: {len(train_items)}, Val items: {len(val_items)}\")\n",
        "print(f\"Number of classes: {len(unique_s2_cells)}\")\n"
      ],
      "metadata": {
        "id": "jX_QCLR0hHni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Enhanced Dataset with better augmentations ---\n",
        "class GeoImageDataset(Dataset):\n",
        "    def __init__(self, items, transform=None, is_training=True):\n",
        "        self.items = items\n",
        "        self.transform = transform\n",
        "        self.is_training = is_training\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            item = self.items[idx]\n",
        "            img = Image.open(item[\"img_path\"]).convert(\"RGB\")\n",
        "\n",
        "            if self.transform:\n",
        "                if self.is_training and hasattr(self.transform, 'transforms'):\n",
        "                    # Albumentations\n",
        "                    img_array = np.array(img)\n",
        "                    transformed = self.transform(image=img_array)\n",
        "                    img = transformed[\"image\"]\n",
        "                else:\n",
        "                    # Torchvision\n",
        "                    img = self.transform(img)\n",
        "\n",
        "            return img, idx, item[\"label\"], item[\"lat\"], item[\"lon\"]\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image at index {idx}: {e}\")\n",
        "            # Return a dummy image\n",
        "            dummy_img = torch.zeros(3, 384, 384)\n",
        "            return dummy_img, idx, 0, 0.0, 0.0\n"
      ],
      "metadata": {
        "id": "5h-qoqKFhHlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced augmentations using Albumentations\n",
        "def get_train_transforms(size=384):\n",
        "    return A.Compose([\n",
        "        A.RandomResizedCrop(height=size, width=size, size=(size, size), scale=(0.7, 1.0), ratio=(0.75, 1.33)),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.1),\n",
        "        A.RandomRotate90(p=0.3),\n",
        "        A.OneOf([\n",
        "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.8),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.8),\n",
        "        ], p=0.9),\n",
        "        A.OneOf([\n",
        "            A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
        "            A.MotionBlur(blur_limit=(3, 7), p=0.5),\n",
        "        ], p=0.3),\n",
        "        A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.2),\n",
        "        A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0.5, p=0.2),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_val_transforms(size=384):\n",
        "    return A.Compose([\n",
        "        A.Resize(height=size, width=size, size=(size, size)),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "train_ds = GeoImageDataset(train_items, transform=get_train_transforms(384), is_training=True)\n",
        "val_ds = GeoImageDataset(val_items, transform=get_val_transforms(384), is_training=False)"
      ],
      "metadata": {
        "id": "f_akeEwGhgCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Weighted sampling for imbalanced classes\n",
        "def get_weighted_sampler(dataset):\n",
        "    label_counts = {}\n",
        "    for item in dataset.items:\n",
        "        label = item[\"label\"]\n",
        "        label_counts[label] = label_counts.get(label, 0) + 1\n",
        "\n",
        "    weights = []\n",
        "    for item in dataset.items:\n",
        "        label = item[\"label\"]\n",
        "        weight = 1.0 / label_counts[label]\n",
        "        weights.append(weight)\n",
        "\n",
        "    return WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "train_sampler = get_weighted_sampler(train_ds)\n",
        "train_loader = DataLoader(train_ds, batch_size=16, sampler=train_sampler, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "KWhyBfQShHjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Step 4: Enhanced Model Definition ---\n",
        "# Since we can't download the actual geofuse.py, let's define a mock model\n",
        "class GeoFuse(nn.Module):\n",
        "    def __init__(self, backbone_name=\"efficientnet_b3\", num_classes=None, embed_dim=512):\n",
        "        super().__init__()\n",
        "        import timm\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=True, num_classes=0)\n",
        "\n",
        "        # Get backbone output dimension\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.randn(1, 3, 384, 384)\n",
        "            backbone_out_dim = self.backbone(dummy_input).shape[1]\n",
        "\n",
        "        self.descriptor_head = nn.Sequential(\n",
        "            nn.Linear(backbone_out_dim, embed_dim),\n",
        "            nn.BatchNorm1d(embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "        if num_classes:\n",
        "            self.classifier = nn.Linear(embed_dim, num_classes)\n",
        "        else:\n",
        "            self.classifier = None\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        descriptor = self.descriptor_head(features)\n",
        "\n",
        "        logits = None\n",
        "        if self.classifier is not None:\n",
        "            logits = self.classifier(descriptor)\n",
        "\n",
        "        return descriptor, logits, features, None\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = GeoFuse(\n",
        "    backbone_name=\"efficientnet_b3\",\n",
        "    num_classes=len(unique_s2_cells),\n",
        "    embed_dim=512\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "JlpuUQqmhnnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss functions and optimizer\n",
        "criterion_cls = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-4,\n",
        "    betas=(0.9, 0.999)\n",
        ")"
      ],
      "metadata": {
        "id": "gxXANUzHhnlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=5, T_mult=2, eta_min=1e-6\n",
        ")"
      ],
      "metadata": {
        "id": "FemwLnDVhni3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Improved Hard Negative Miner ---\n",
        "class HardNegativeMiner:\n",
        "    def __init__(self, model, device, batch_size=32):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.index = None\n",
        "        self.descriptors = None\n",
        "\n",
        "    def extract_descriptors(self, dataset):\n",
        "        \"\"\"Extract descriptors for all samples in the dataset\"\"\"\n",
        "        self.model.eval()\n",
        "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "        descriptors = []\n",
        "        labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, idxs, lbls, lats, lons in tqdm(loader, desc=\"Extracting descriptors\"):\n",
        "                imgs = imgs.to(self.device)\n",
        "                desc, _, _, _ = self.model(imgs)\n",
        "                desc = F.normalize(desc, p=2, dim=1)\n",
        "                descriptors.append(desc.cpu())\n",
        "                labels.extend(lbls.numpy())\n",
        "\n",
        "        self.descriptors = torch.cat(descriptors, dim=0).numpy().astype(\"float32\")\n",
        "        self.labels = np.array(labels)\n",
        "\n",
        "        # Build FAISS index\n",
        "        self.index = faiss.IndexFlatIP(self.descriptors.shape[1])  # Inner Product for cosine similarity\n",
        "        self.index.add(self.descriptors)\n",
        "\n",
        "        return self.descriptors\n",
        "\n",
        "    def mine_hard_negatives(self, top_k=20, same_class_ratio=0.3):\n",
        "        \"\"\"Mine hard negatives with both inter-class and intra-class negatives\"\"\"\n",
        "        if self.index is None:\n",
        "            raise ValueError(\"Must extract descriptors first\")\n",
        "\n",
        "        hard_negatives = {}\n",
        "\n",
        "        for i in range(len(self.descriptors)):\n",
        "            # Search for most similar samples\n",
        "            scores, indices = self.index.search(self.descriptors[i:i+1], top_k * 3)\n",
        "\n",
        "            current_label = self.labels[i]\n",
        "            negatives = []\n",
        "            same_class_negs = []\n",
        "            diff_class_negs = []\n",
        "\n",
        "            for idx in indices[0]:\n",
        "                if idx == i:\n",
        "                    continue\n",
        "\n",
        "                if self.labels[idx] == current_label:\n",
        "                    same_class_negs.append(idx)\n",
        "                else:\n",
        "                    diff_class_negs.append(idx)\n",
        "\n",
        "            # Mix same-class and different-class negatives\n",
        "            num_same_class = min(len(same_class_negs), int(top_k * same_class_ratio))\n",
        "            num_diff_class = min(len(diff_class_negs), top_k - num_same_class)\n",
        "\n",
        "            negatives.extend(same_class_negs[:num_same_class])\n",
        "            negatives.extend(diff_class_negs[:num_diff_class])\n",
        "\n",
        "            hard_negatives[i] = negatives\n",
        "\n",
        "        return hard_negatives\n",
        "\n",
        "# Initialize hard negative miner\n",
        "hn_miner = HardNegativeMiner(model, device, batch_size=32)\n"
      ],
      "metadata": {
        "id": "eRA594Suhngf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Step 6: Enhanced Training Loop ---\n",
        "def train_epoch(model, train_loader, optimizer, criterion_cls, hard_negatives=None, epoch=0):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_cls_loss = 0\n",
        "    total_ret_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for batch_idx, (imgs, idxs, labels, lats, lons) in enumerate(pbar):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        desc, logits, _, _ = model(imgs)\n",
        "        desc = F.normalize(desc, p=2, dim=1)\n",
        "\n",
        "        # Classification loss\n",
        "        loss_cls = criterion_cls(logits, labels)\n",
        "\n",
        "        # Hard negative mining loss\n",
        "        loss_retrieval = 0.0\n",
        "        if hard_negatives is not None:\n",
        "            for i, anchor_idx in enumerate(idxs):\n",
        "                anchor_idx = anchor_idx.item()\n",
        "                neg_candidates = hard_negatives.get(anchor_idx, [])\n",
        "\n",
        "                if not neg_candidates:\n",
        "                    continue\n",
        "\n",
        "                # Sample multiple negatives for more stable training\n",
        "                num_negs = min(3, len(neg_candidates))\n",
        "                selected_negs = random.sample(neg_candidates, num_negs)\n",
        "\n",
        "                for neg_idx in selected_negs:\n",
        "                    try:\n",
        "                        neg_img, _, neg_label, _, _ = train_ds[neg_idx]\n",
        "                        neg_img = neg_img.unsqueeze(0).to(device)\n",
        "\n",
        "                        with torch.no_grad():\n",
        "                            neg_desc, _, _, _ = model(neg_img)\n",
        "                            neg_desc = F.normalize(neg_desc, p=2, dim=1)\n",
        "\n",
        "                        # Triplet-like loss\n",
        "                        anchor_desc = desc[i].unsqueeze(0)\n",
        "                        pos_sim = torch.cosine_similarity(anchor_desc, anchor_desc, dim=1)\n",
        "                        neg_sim = torch.cosine_similarity(anchor_desc, neg_desc, dim=1)\n",
        "\n",
        "                        margin = 0.5\n",
        "                        triplet_loss = F.relu(neg_sim - pos_sim + margin)\n",
        "                        loss_retrieval += triplet_loss\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "            if len(idxs) > 0:\n",
        "                loss_retrieval = loss_retrieval / len(idxs)\n",
        "\n",
        "        # Combined loss\n",
        "        alpha = 0.2  # Weight for retrieval loss\n",
        "        total_batch_loss = loss_cls + alpha * loss_retrieval\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        total_batch_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        total_loss += total_batch_loss.item()\n",
        "        total_cls_loss += loss_cls.item()\n",
        "        total_ret_loss += loss_retrieval.item() if isinstance(loss_retrieval, torch.Tensor) else loss_retrieval\n",
        "\n",
        "        preds = logits.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += len(labels)\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": total_batch_loss.item(),\n",
        "            \"cls_loss\": loss_cls.item(),\n",
        "            \"ret_loss\": loss_retrieval.item() if isinstance(loss_retrieval, torch.Tensor) else loss_retrieval,\n",
        "            \"acc\": 100 * correct / total\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"loss\": total_loss / len(train_loader),\n",
        "        \"cls_loss\": total_cls_loss / len(train_loader),\n",
        "        \"ret_loss\": total_ret_loss / len(train_loader),\n",
        "        \"accuracy\": 100 * correct / total\n",
        "    }\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion_cls):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, idxs, labels, lats, lons in tqdm(val_loader, desc=\"Validation\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            desc, logits, _, _ = model(imgs)\n",
        "            loss = criterion_cls(logits, labels)\n",
        "\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += len(labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "\n",
        "    return {\n",
        "        \"loss\": avg_loss,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"predictions\": all_preds,\n",
        "        \"labels\": all_labels\n",
        "    }"
      ],
      "metadata": {
        "id": "nYjmM8qHhneN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Training Loop ---\n",
        "num_epochs = 15\n",
        "best_val_acc = 0\n",
        "hard_negatives = None\n",
        "train_history = []\n",
        "val_history = []\n",
        "\n",
        "print(\"üöÄ Starting training...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Mine hard negatives every 3 epochs\n",
        "    if epoch % 3 == 0:\n",
        "        print(f\"\\nüîç Mining hard negatives for epoch {epoch+1}...\")\n",
        "        try:\n",
        "            hn_miner.extract_descriptors(train_ds)\n",
        "            hard_negatives = hn_miner.mine_hard_negatives(top_k=15, same_class_ratio=0.3)\n",
        "            print(f\"‚úÖ Mined hard negatives for {len(hard_negatives)} samples\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Hard negative mining failed: {e}\")\n",
        "            hard_negatives = None\n",
        "\n",
        "    # Training\n",
        "    train_metrics = train_epoch(model, train_loader, optimizer, criterion_cls, hard_negatives, epoch)\n",
        "    train_history.append(train_metrics)\n",
        "\n",
        "    # Validation\n",
        "    val_metrics = validate_epoch(model, val_loader, criterion_cls)\n",
        "    val_history.append(val_metrics)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train - Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.2f}%\")\n",
        "    print(f\"Val   - Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.2f}%\")\n",
        "    print(f\"LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_metrics['accuracy'] > best_val_acc:\n",
        "        best_val_acc = val_metrics['accuracy']\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_val_acc': best_val_acc,\n",
        "            's2_to_label': s2_to_label,\n",
        "            'label_to_s2': label_to_s2,\n",
        "        }, \"best_geofuse_osv5m.pth\")\n",
        "        print(f\"üíæ New best model saved! Val Acc: {best_val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "fPbQHuyBhnbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final model save\n",
        "torch.save({\n",
        "    'epoch': num_epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler_state_dict': scheduler.state_dict(),\n",
        "    'val_acc': val_metrics['accuracy'],\n",
        "    's2_to_label': s2_to_label,\n",
        "    'label_to_s2': label_to_s2,\n",
        "    'train_history': train_history,\n",
        "    'val_history': val_history,\n",
        "}, \"final_geofuse_osv5m.pth\")\n",
        "\n",
        "print(f\"\\nüéâ Training completed!\")\n",
        "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"Final validation accuracy: {val_metrics['accuracy']:.2f}%\")\n"
      ],
      "metadata": {
        "id": "f9WNKTu8hnWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation and Visualization ---\n",
        "def plot_training_history(train_history, val_history):\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    # Loss curves\n",
        "    train_losses = [h['loss'] for h in train_history]\n",
        "    val_losses = [h['loss'] for h in val_history]\n",
        "\n",
        "    ax1.plot(train_losses, label='Train Loss', color='blue')\n",
        "    ax1.plot(val_losses, label='Val Loss', color='red')\n",
        "    ax1.set_title('Loss Curves')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Accuracy curves\n",
        "    train_accs = [h['accuracy'] for h in train_history]\n",
        "    val_accs = [h['accuracy'] for h in val_history]\n",
        "\n",
        "    ax2.plot(train_accs, label='Train Acc', color='blue')\n",
        "    ax2.plot(val_accs, label='Val Acc', color='red')\n",
        "    ax2.set_title('Accuracy Curves')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy (%)')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # Classification loss\n",
        "    train_cls_losses = [h['cls_loss'] for h in train_history]\n",
        "    ax3.plot(train_cls_losses, label='Classification Loss', color='green')\n",
        "    ax3.set_title('Classification Loss')\n",
        "    ax3.set_xlabel('Epoch')\n",
        "    ax3.set_ylabel('Loss')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True)\n",
        "\n",
        "    # Retrieval loss\n",
        "    train_ret_losses = [h['ret_loss'] for h in train_history]\n",
        "    ax4.plot(train_ret_losses, label='Retrieval Loss', color='orange')\n",
        "    ax4.set_title('Retrieval Loss')\n",
        "    ax4.set_xlabel('Epoch')\n",
        "    ax4.set_ylabel('Loss')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zbjkvmx6hHbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot training history\n",
        "plot_training_history(train_history, val_history)\n",
        "\n",
        "print(\"‚úÖ Training analysis completed. Check 'training_history.png' for visualizations.\")\n",
        "print(\"‚úÖ Models saved as 'best_geofuse_osv5m.pth' and 'final_geofuse_osv5m.pth'\")"
      ],
      "metadata": {
        "id": "2iwPATthh_kZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}